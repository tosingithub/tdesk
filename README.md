# Exploring Swedish &amp; English fastText Embeddings with the Transformer

<h4>Codes:</h4>
One source code file is for English NER and the other for Swedish NER, while there's a general purpose file also. The preprocessed Wikipedia dump (4.2G) can be downloaded from <a href="https://drive.google.com/file/d/1zngnD_bQBxA_8TdQnAYXjTK4EukGJP4N/view?usp=sharing">here</a>.

<h4>Models are available upon request:</h4>


<h4>License:</h4>
All codes and models are released under CC-BY 4.0.

<h4>Contact:</h4>
Feel free to contact me for further enquiry.

<h4>How do I cite?</h4>
For now, please cite the relevant Arxiv paper (or the 2nd one, for the Corpora Compared paper presented at SLTC 2020):

<pre><code>
@article{adewumi2020exploring,
  title={Exploring Swedish & English fastText Embeddings with the Transformer},
  author={Adewumi, Tosin P and Liwicki, Foteini and Liwicki, Marcus},
  journal={arXiv preprint arXiv:2007.16007},
  year={2020}
}
</code></pre>


<pre><code>
@article{adewumi2020corpora,
  title={Corpora Compared: The Case of the Swedish Gigaword \& Wikipedia Corpora},
  author={Adewumi, Tosin P and Liwicki, Foteini and Liwicki, Marcus},
  journal={arXiv preprint arXiv:2011.03281},
  year={2020}
}
</code></pre>
